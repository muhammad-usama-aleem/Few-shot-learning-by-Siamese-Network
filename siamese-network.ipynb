{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np\nimport os\n\nimport tensorflow as tf\nimport keras\nfrom keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\nfrom keras.models import Model, Sequential\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.optimizers import SGD,Adam\nfrom keras.losses import binary_crossentropy\nfrom keras.utils import plot_model","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-03-10T01:47:01.350500Z","iopub.execute_input":"2022-03-10T01:47:01.350859Z","iopub.status.idle":"2022-03-10T01:47:05.674404Z","shell.execute_reply.started":"2022-03-10T01:47:01.350827Z","shell.execute_reply":"2022-03-10T01:47:05.673499Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing","metadata":{}},{"cell_type":"code","source":"base_dir = r'../input/fruits/fruits-360_dataset/fruits-360/Training/'\ntrain_test_split = 0.7\nno_of_files_in_each_class = 10\n\n#Read all the folders in the directory\nfolder_list = os.listdir(base_dir)\nprint( len(folder_list), \"categories found in the dataset\")\n\n#Declare training array\ncat_list = []\nx = []\ny = []\ny_label = 0\n\n#Using just 5 images per category\nfor folder_name in folder_list:\n    files_list = os.listdir(os.path.join(base_dir, folder_name))\n    temp=[]\n    for file_name in files_list[:no_of_files_in_each_class]:\n        temp.append(len(x))\n        x.append(np.asarray(Image.open(os.path.join(base_dir, folder_name, file_name)).convert('RGB').resize((100, 100))))\n        y.append(y_label)\n    y_label+=1\n    cat_list.append(temp)\n\ncat_list = np.asarray(cat_list)\nx = np.asarray(x)/255.0\ny = np.asarray(y)\nprint('X, Y shape',x.shape, y.shape, cat_list.shape)        ","metadata":{"execution":{"iopub.status.busy":"2022-03-10T01:53:59.636938Z","iopub.execute_input":"2022-03-10T01:53:59.637354Z","iopub.status.idle":"2022-03-10T01:54:36.522517Z","shell.execute_reply.started":"2022-03-10T01:53:59.637313Z","shell.execute_reply":"2022-03-10T01:54:36.521799Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Train test split","metadata":{}},{"cell_type":"code","source":"train_size = int(len(folder_list)*train_test_split)\ntest_size = len(folder_list) - train_size\nprint(train_size, 'classes for training and', test_size, ' classes for testing')\n\ntrain_files = train_size * no_of_files_in_each_class\n\n#Training Split\nx_train = x[:train_files]\ny_train = y[:train_files]\ncat_train = cat_list[:train_size]\n\n#Validation Split\nx_val = x[train_files:]\ny_val = y[train_files:]\ncat_test = cat_list[train_size:]\n\nprint('X&Y shape of training data :',x_train.shape, 'and', y_train.shape, cat_train.shape)\nprint('X&Y shape of testing data :' , x_val.shape, 'and', y_val.shape, cat_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T01:55:02.853269Z","iopub.execute_input":"2022-03-10T01:55:02.853581Z","iopub.status.idle":"2022-03-10T01:55:02.864265Z","shell.execute_reply.started":"2022-03-10T01:55:02.853551Z","shell.execute_reply":"2022-03-10T01:55:02.862954Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Plotting Images\nfor i in range(0,9):\n    plt.subplot(3, 3, i+1)\n    plt.axis('off')\n    plt.imshow(x_train[np.random.randint(0, x_train.shape[0]-1)])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T01:55:09.736034Z","iopub.execute_input":"2022-03-10T01:55:09.737785Z","iopub.status.idle":"2022-03-10T01:55:10.160129Z","shell.execute_reply.started":"2022-03-10T01:55:09.737738Z","shell.execute_reply":"2022-03-10T01:55:10.159217Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Generating Batch","metadata":{}},{"cell_type":"code","source":"def get_batch(batch_size=64, call_type='train'):\n    \n    temp_x = None\n    temp_cat_list = None\n    start=None\n    end=None\n    batch_x=[]\n    \n    if call_type == 'train':\n        temp_x = x_train\n        temp_cat_list = cat_train\n        start=0\n        end = train_size\n    else:\n        temp_x = x_val\n        temp_cat_list = cat_test\n        start = train_size+1\n        end = len(folder_list)-1\n        \n    batch_y = np.zeros(batch_size)\n    batch_y[int(batch_size/2):] = 1\n    np.random.shuffle(batch_y)\n    \n    class_list = np.random.randint(start, end, batch_size) \n    batch_x.append(np.zeros((batch_size, 100, 100, 3)))\n    batch_x.append(np.zeros((batch_size, 100, 100, 3)))\n\n    for i in range(0, batch_size):\n        batch_x[0][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]  \n        #If train_y has 0 pick from the same class, else pick from any other class\n        if batch_y[i]==0:\n            batch_x[1][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n\n        else:\n            temp_list = np.append(temp_cat_list[:class_list[i]].flatten(), temp_cat_list[class_list[i]+1:].flatten())\n            batch_x[1][i] = temp_x[np.random.choice(temp_list)]\n            \n    return(batch_x, batch_y)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T01:56:26.189092Z","iopub.execute_input":"2022-03-10T01:56:26.189408Z","iopub.status.idle":"2022-03-10T01:56:26.202537Z","shell.execute_reply.started":"2022-03-10T01:56:26.189379Z","shell.execute_reply":"2022-03-10T01:56:26.201333Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Siamese Network","metadata":{}},{"cell_type":"code","source":"#Building a sequential model\ninput_shape=(100, 100, 3)\nleft_input = Input(input_shape)\nright_input = Input(input_shape)\n\nW_init = keras.initializers.RandomNormal(mean = 0.0, stddev = 1e-2)\nb_init = keras.initializers.RandomNormal(mean = 0.5, stddev = 1e-2)\n\nmodel = keras.models.Sequential([\n    keras.layers.Conv2D(64, (10,10), activation='relu', input_shape=input_shape, kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n    keras.layers.MaxPooling2D(2, 2),\n    keras.layers.Conv2D(128, (7,7), activation='relu', kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Conv2D(128, (4,4), activation='relu', kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Conv2D(256, (4,4), activation='relu', kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n    keras.layers.MaxPooling2D(2,2),\n    keras.layers.Flatten(),\n    keras.layers.Dense(4096, activation='sigmoid', kernel_initializer=W_init, bias_initializer=b_init)\n])\n\nencoded_l = model(left_input)\nencoded_r = model(right_input)\n\n# L1_distance = lambda x: K.abs(x[0] - x[1])\n# print(type(L1_distance))\n# both = merge([encoded_l, encoded_r], mode=L1_distance, output_shape = lambda x:x[0])\nsubtracted = keras.layers.Subtract()([encoded_l, encoded_r])\nprediction = Dense(1, activation='sigmoid', bias_initializer=b_init)(subtracted)\nsiamese_net = Model(input=[left_input, right_input], output=prediction)\n\noptimizer= Adam(learning_rate=0.0006)\nsiamese_net.compile(loss='binary_crossentropy', optimizer=optimizer)\n\noptimizer = Adam(lr = 0.00006)\nmodel.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n\nplot_model(siamese_net, show_shapes=True, show_layer_names=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T01:56:34.022132Z","iopub.execute_input":"2022-03-10T01:56:34.022446Z","iopub.status.idle":"2022-03-10T01:56:37.099385Z","shell.execute_reply.started":"2022-03-10T01:56:34.022417Z","shell.execute_reply":"2022-03-10T01:56:37.098428Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### N-way One shot learning","metadata":{}},{"cell_type":"code","source":"def nway_one_shot(model, n_way, n_val):\n    \n    temp_x = x_val\n    temp_cat_list = cat_test\n    batch_x=[]\n    x_0_choice=[]\n    n_correct = 0\n   \n    class_list = np.random.randint(train_size+1, len(folder_list)-1, n_val)\n\n    for i in class_list:  \n        j = np.random.choice(cat_list[i])\n        temp=[]\n        temp.append(np.zeros((n_way, 100, 100, 3)))\n        temp.append(np.zeros((n_way, 100, 100, 3)))\n        for k in range(0, n_way):\n            temp[0][k] = x[j]\n            \n            if k==0:\n                #print(i, k, j, np.random.choice(cat_list[i]))\n                temp[1][k] = x[np.random.choice(cat_list[i])]\n            else:\n                #print(i, k, j, np.random.choice(np.append(cat_list[:i].flatten(), cat_list[i+1:].flatten())))\n                temp[1][k] = x[np.random.choice(np.append(cat_list[:i].flatten(), cat_list[i+1:].flatten()))]\n\n        result = siamese_net.predict(temp)\n        result = result.flatten().tolist()\n        result_index = result.index(min(result))\n        if result_index == 0:\n            n_correct = n_correct + 1\n    print(n_correct, \"correctly classified among\", n_val)\n    accuracy = (n_correct*100)/n_val\n    return accuracy\n            ","metadata":{"execution":{"iopub.status.busy":"2022-03-10T01:56:56.656344Z","iopub.execute_input":"2022-03-10T01:56:56.656690Z","iopub.status.idle":"2022-03-10T01:56:56.669025Z","shell.execute_reply.started":"2022-03-10T01:56:56.656656Z","shell.execute_reply":"2022-03-10T01:56:56.668135Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"nway_one_shot(model, 5, 7)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T01:57:02.594237Z","iopub.execute_input":"2022-03-10T01:57:02.594562Z","iopub.status.idle":"2022-03-10T01:57:05.530935Z","shell.execute_reply.started":"2022-03-10T01:57:02.594531Z","shell.execute_reply":"2022-03-10T01:57:05.530085Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Model Training","metadata":{}},{"cell_type":"code","source":"epochs = 5000\nn_way = 20\nn_val = 100\nbatch_size = 64\n\nloss_list=[]\naccuracy_list=[]\nfor epoch in range(1,epochs):\n    batch_x, batch_y = get_batch(batch_size, call_type=\"train\")\n    loss = siamese_net.train_on_batch(batch_x, batch_y)\n    loss_list.append((epoch,loss))\n    print('Epoch:', epoch, ', Loss:',loss)\n    if epoch%50 == 0:\n        print(\"=============================================\")\n        accuracy = nway_one_shot(model, n_way, n_val)\n        accuracy_list.append((epoch, accuracy))\n        print('Accuracy as of', epoch, 'epochs:', accuracy)\n        print(\"=============================================\")\n        if(accuracy>99):\n            print(\"Achieved more than 90% Accuracy\")\n            #break","metadata":{"execution":{"iopub.status.busy":"2022-03-10T01:57:12.034791Z","iopub.execute_input":"2022-03-10T01:57:12.035129Z","iopub.status.idle":"2022-03-10T02:05:54.089601Z","shell.execute_reply.started":"2022-03-10T01:57:12.035098Z","shell.execute_reply":"2022-03-10T02:05:54.088880Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}